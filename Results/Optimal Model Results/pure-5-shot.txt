5-shot:

 Inference complete!
   Total: 3957
   Success: 3872 (97.9%)
   Failed: 85
   
============================================================
LLAMA HATE SPEECH MODEL EVALUATION
============================================================

 Using predictions from: llama_test_predictions_vllm.jsonl

 Data Summary:
   Total samples: 3957
    Valid predictions: 3872 (97.9%)
    Failed predictions: 85 (2.1%)

============================================================
EVALUATION RESULTS
============================================================

============================================================
1. OVERALL: Label Classification
============================================================
Accuracy:        0.6710
Macro F1:        0.6619
Micro F1:        0.6710
Macro Precision: 0.6742
Macro Recall:    0.6593

Per-class breakdown:
              precision    recall  f1-score   support

     hateful       0.72      0.64      0.68      1032
     neutral       0.47      0.61      0.53      1113
  supportive       0.82      0.73      0.77      1727

    accuracy                           0.67      3872
   macro avg       0.67      0.66      0.66      3872
weighted avg       0.70      0.67      0.68      3872

Score Spearman correlation: 0.7826

============================================================
2. FACETS: Ordinal Ratings (0-4 scale)
============================================================
Mean MAE:               0.6260
Mean MSE:               0.8815
Mean Spearman:          0.5415
Mean Exact Match:       0.4915
Mean Within-1 Accuracy: 0.8915

Per-facet breakdown:
Facet                MAE      Exact    Within-1   Spearman  
------------------------------------------------------------
sentiment            0.568    0.535    0.908      0.717     
respect              0.613    0.506    0.899      0.691     
insult               0.796    0.400    0.818      0.617     
humiliate            0.751    0.409    0.850      0.587     
status               0.518    0.578    0.904      0.416     
dehumanize           0.795    0.397    0.818      0.505     
violence             0.613    0.495    0.907      0.459     
genocide             0.519    0.536    0.954      0.292     
attack_defend        0.608    0.486    0.909      0.567     
hatespeech           0.479    0.573    0.948      0.563     

============================================================
3. TARGETS: Multi-label Classification
============================================================
Micro F1:          0.5629
Macro F1:          0.3613
Micro Precision:   0.7119
Micro Recall:      0.4655
Hamming Loss:      0.0408
Exact Match Ratio: 0.3148 (1219/3872)

Per-target F1 scores (bottom 10):
  target_gender_other                      0.000
  target_age_other                         0.000
  target_disability_hearing_impaired       0.000
  target_disability_other                  0.000
  target_origin_other                      0.013
  target_race_other                        0.043
  target_gender_non_binary                 0.081
  target_disability_unspecific             0.082
  target_religion_buddhist                 0.109
  target_age_young_adults                  0.121

============================================================
SAVING EVALUATION SUMMARY
============================================================
 Summary saved to: llama_evaluation_summary.json
  85 samples failed - check llama_failed_predictions_vllm.jsonl

============================================================
EVALUATION COMPLETE!
============================================================

 KEY METRICS SUMMARY:
   Overall Accuracy: 67.10%
   Overall Macro F1: 0.6619
   Facets Mean MAE:  0.6260
   Targets Micro F1: 0.5629