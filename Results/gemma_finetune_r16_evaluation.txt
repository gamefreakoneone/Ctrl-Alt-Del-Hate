============================================================
HATE SPEECH MODEL EVALUATION
============================================================

 Using predictions from: gemma_test_predictions_vllm.jsonl

 Data Summary:
   Total samples: 3957
    Valid predictions: 3857 (97.5%)
    Failed predictions: 100 (2.5%)

============================================================
EVALUATION RESULTS
============================================================

============================================================
OVERALL: Label Classification (hateful/neutral/supportive)
============================================================
Accuracy:        0.6731
Macro F1:        0.6433
Micro F1:        0.6731
Macro Precision: 0.6505
Macro Recall:    0.6408

Per-class breakdown:
              precision    recall  f1-score   support

     hateful       0.71      0.63      0.67      1027
     neutral       0.49      0.44      0.46      1118
  supportive       0.75      0.85      0.79      1712

    accuracy                           0.67      3857
   macro avg       0.65      0.64      0.64      3857
weighted avg       0.66      0.67      0.67      3857


Score Spearman correlation: 0.7861

============================================================
FACETS: Ordinal Ratings (0-4 scale)
============================================================
Mean MAE:              0.5339
Mean MSE:              0.7090
Mean Spearman:         0.5750
Mean Exact Match:      0.5479
Mean Within-1 Accuracy: 0.9234

Per-facet breakdown:
Facet                MAE      Exact    Within-1   Spearman  
------------------------------------------------------------
sentiment            0.495    0.551    0.957      0.704     
respect              0.556    0.508    0.941      0.697     
insult               0.639    0.466    0.906      0.673     
humiliate            0.670    0.434    0.903      0.631     
status               0.443    0.597    0.961      0.470     
dehumanize           0.775    0.388    0.841      0.469     
violence             0.548    0.567    0.897      0.503     
genocide             0.334    0.734    0.939      0.414     
attack_defend        0.516    0.538    0.949      0.585     
hatespeech           0.363    0.697    0.939      0.605     

============================================================
TARGETS: Multi-label Classification
============================================================
Micro F1:          0.5752
Macro F1:          0.3433
Micro Precision:   0.7627
Micro Recall:      0.4617
Hamming Loss:      0.0386
Exact Match Ratio: 0.3635 (1402/3857)

Per-target F1 scores (bottom 10):
  target_origin_other                      0.000
  target_gender_other                      0.000
  target_age_other                         0.000
  target_disability_physical               0.000
  target_disability_neurological           0.000
  target_disability_visually_impaired      0.000
  target_disability_hearing_impaired       0.000
  target_disability_unspecific             0.000
  target_disability_other                  0.000
  target_age_middle_aged                   0.062

============================================================
SAVING EVALUATION SUMMARY
============================================================
 Summary saved to: evaluation_summary.json
  100 samples failed - check failed_predictions_*.jsonl

============================================================
EVALUATION COMPLETE!
============================================================

 KEY METRICS SUMMARY:
   Overall Accuracy: 67.31%
   Overall Macro F1: 0.6433
   Facets Mean MAE:  0.5339
   Targets Micro F1: 0.5752
