{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629aefd4",
   "metadata": {},
   "source": [
    "Midterm Report:\n",
    "Week 1\n",
    "1. Benchmarks: Gemma 3 (4 Billion) and Llama 3 (Llama 3.2 3B)\n",
    "2. Dataset: UCBerkely\n",
    "\n",
    "\n",
    "Week 2:\n",
    "1. Finetuning of Gemma 3 and Llama 3.2 3B with LoRA , and if necesasary QLoRA (maybe for endterm report). [Finetuning Benchmarks]\n",
    "2. Evaluation of other opensource models with more parameters (low priority)\n",
    "\n",
    "\n",
    "Week 3:\n",
    "TBD\n",
    "1. Start working on report and final exam.\n",
    "2. Prompting strategies for Gemma 3 and Llama 3.2 3B which can improve performance.\n",
    "3. Again perform evaluation on unfinetuned performed models with improved prompting strategies. (low priority)\n",
    "\n",
    "\n",
    "After Midterm Exam:\n",
    "1. We will focus on improving parameters of LoRA and QLoRA.\n",
    "2. Also work on improvements suggested in midterm report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d43d12",
   "metadata": {},
   "source": [
    "<!-- # Proposed Schema\n",
    "\n",
    "Input schema for finetuningb and ground truth:\n",
    "```\n",
    "{\n",
    "  \"overall\": {\"label\": \"none|abusive|hateful\", \"score\": 0.0},\n",
    "  \"facets\": {\n",
    "    \"insult\": 0, \"humiliate\": 0, \"dehumanize\": 0,\n",
    "    \"violence\": 0, \"genocide\": 0,\n",
    "    \"respect\": 0, \"status\": 0, \"attack_defend\": 0, \"sentiment\": 0\n",
    "  },\n",
    "  \"targets\": {\n",
    "    \"race_asian\": false, \"race_black\": false, \"race_white\": false, \"race_latinx\": false,\n",
    "    \"religion_muslim\": false, \"religion_jewish\": false, \"religion_hindu\": false, \"religion_buddhist\": false,\n",
    "    \"gender_men\": false, \"gender_women\": false, \"gender_transgender\": false, \"gender_non_binary\": false,\n",
    "    \"sexuality_gay\": false, \"sexuality_lesbian\": false, \"sexuality_bisexual\": false, \"sexuality_straight\": false,\n",
    "    \"disability_physical\": false, \"disability_cognitive\": false, \"origin_immigrant\": false, \"other\": false\n",
    "  },\n",
    "  \"explanation\" : \"text\",\n",
    "}``` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb711d",
   "metadata": {},
   "source": [
    "# Gold Standard Dataset schema\n",
    "\n",
    "```\n",
    "{\n",
    "  // --- Core Identifiers ---\n",
    "  \"comment_id\": \"131169.0\", \n",
    "  \"text\": \"The original text content of the social media comment.\",\n",
    "\n",
    "  // --- Holistic Overall Assessment ---\n",
    "  \"overall\": {\n",
    "    \"label\": \"hateful\",             // A categorical label derived from the paper's official thresholds.\n",
    "                                    // - \"hateful\": If hate_speech_score > 0.5\n",
    "                                    // - \"supportive\": If hate_speech_score < -1.0\n",
    "                                    // - \"neutral\": If between -1.0 and 0.5 (inclusive)\n",
    "    \"hate_speech_score\": 1.52       // Ground truth \n",
    "  },\n",
    "\n",
    "  // --- Multi-Label Facet Analysis (The Core of the Task) ---\n",
    "  \"facets\": {\n",
    "    \"sentiment\": 3.0,               \n",
    "    \"respect\": 3.0,                 \n",
    "    \"insult\": 3.0,                  \n",
    "    \"humiliate\": 3.0,\n",
    "    \"status\": 0.0,\n",
    "    \"dehumanize\": 3.0,\n",
    "    \"violence\": 0.0,\n",
    "    \"genocide\": 0.0,\n",
    "    \"attack_defend\": 3.0,\n",
    "    \"hatespeech\": 1.0               \n",
    "  },\n",
    "\n",
    "  // --- Multi-Label Target Group Identification ---\n",
    "  \"targets\": {\n",
    "    \"race_asian\": true,             // A dictionary of booleans. `true` means the comment targets this group.\n",
    "    \"race_black\": false,            // This allows a single comment to target multiple groups simultaneously.\n",
    "    \"religion_muslim\": true,\n",
    "    \"gender_women\": false\n",
    "    // ... and so on for all other possible target groups.\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a5fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset into a pandas DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinh2\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 135556 rows and 131 columns.\n",
      "Applying the transformation to each row of the DataFrame...\n",
      "\n",
      "Example of a processed record:\n",
      "{\n",
      "  \"comment_id\": 47777,\n",
      "  \"text\": \"Yes indeed. She sort of reminds me of the elder lady that played the part in the movie \\\"Titanic\\\" who was telling her story!!! And I wouldn't have wanted to cover who I really am!! I would be proud!!!! WE should be proud of our race no matter what it is!!\",\n",
      "  \"overall\": {\n",
      "    \"label\": \"supportive\",\n",
      "    \"hate_speech_score\": -3.9\n",
      "  },\n",
      "  \"facets\": {\n",
      "    \"sentiment\": 0.0,\n",
      "    \"respect\": 0.0,\n",
      "    \"insult\": 0.0,\n",
      "    \"humiliate\": 0.0,\n",
      "    \"status\": 2.0,\n",
      "    \"dehumanize\": 0.0,\n",
      "    \"violence\": 0.0,\n",
      "    \"genocide\": 0.0,\n",
      "    \"attack_defend\": 0.0,\n",
      "    \"hatespeech\": 0.0\n",
      "  },\n",
      "  \"targets\": {\n",
      "    \"target_race_asian\": true,\n",
      "    \"target_race_black\": true,\n",
      "    \"target_race_latinx\": true,\n",
      "    \"target_race_middle_eastern\": true,\n",
      "    \"target_race_native_american\": true,\n",
      "    \"target_race_pacific_islander\": true,\n",
      "    \"target_race_white\": true,\n",
      "    \"target_race_other\": false,\n",
      "    \"target_religion_atheist\": false,\n",
      "    \"target_religion_buddhist\": false,\n",
      "    \"target_religion_christian\": false,\n",
      "    \"target_religion_hindu\": false,\n",
      "    \"target_religion_jewish\": false,\n",
      "    \"target_religion_mormon\": false,\n",
      "    \"target_religion_muslim\": false,\n",
      "    \"target_religion_other\": false,\n",
      "    \"target_origin_immigrant\": false,\n",
      "    \"target_origin_migrant_worker\": false,\n",
      "    \"target_origin_specific_country\": false,\n",
      "    \"target_origin_undocumented\": false,\n",
      "    \"target_origin_other\": false,\n",
      "    \"target_gender_men\": false,\n",
      "    \"target_gender_non_binary\": false,\n",
      "    \"target_gender_transgender_men\": false,\n",
      "    \"target_gender_transgender_unspecified\": false,\n",
      "    \"target_gender_transgender_women\": false,\n",
      "    \"target_gender_women\": false,\n",
      "    \"target_gender_other\": false,\n",
      "    \"target_sexuality_bisexual\": false,\n",
      "    \"target_sexuality_gay\": false,\n",
      "    \"target_sexuality_lesbian\": false,\n",
      "    \"target_sexuality_straight\": false,\n",
      "    \"target_sexuality_other\": false,\n",
      "    \"target_disability_physical\": false,\n",
      "    \"target_disability_cognitive\": false,\n",
      "    \"target_disability_neurological\": false,\n",
      "    \"target_disability_visually_impaired\": false,\n",
      "    \"target_disability_hearing_impaired\": false,\n",
      "    \"target_disability_unspecific\": false,\n",
      "    \"target_disability_other\": false\n",
      "  }\n",
      "}\n",
      "\n",
      "Saving the 135556 records to 'gold_benchmark_dataset.jsonl'...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Note: This script requires the following libraries to be installed:\n",
    "# pip install pandas pyarrow fsspec huggingface_hub\n",
    "\n",
    "# 1. Load the dataset into a pandas DataFrame (your preferred method)\n",
    "print(\"Loading the dataset into a pandas DataFrame...\")\n",
    "try:\n",
    "    df = pd.read_parquet(\"hf://datasets/ucberkeley-dlab/measuring-hate-speech/measuring-hate-speech.parquet\")\n",
    "    print(f\"Dataset loaded successfully with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the data: {e}\")\n",
    "    print(\"Please ensure you have run 'pip install pandas pyarrow fsspec huggingface_hub'\")\n",
    "    exit()\n",
    "\n",
    "# 2. Define the columns we want to extract\n",
    "# These are the actual facet and target columns present in the dataset\n",
    "FACET_COLUMNS = [\n",
    "    'sentiment', 'respect', 'insult', 'humiliate', 'status', 'dehumanize', \n",
    "    'violence', 'genocide', 'attack_defend', 'hatespeech'\n",
    "]\n",
    "\n",
    "TARGET_COLUMNS = [\n",
    "    'target_race_asian', 'target_race_black', 'target_race_latinx', \n",
    "    'target_race_middle_eastern', 'target_race_native_american', \n",
    "    'target_race_pacific_islander', 'target_race_white', 'target_race_other',\n",
    "    'target_religion_atheist', 'target_religion_buddhist', 'target_religion_christian',\n",
    "    'target_religion_hindu', 'target_religion_jewish', 'target_religion_mormon',\n",
    "    'target_religion_muslim', 'target_religion_other', 'target_origin_immigrant',\n",
    "    'target_origin_migrant_worker', 'target_origin_specific_country',\n",
    "    'target_origin_undocumented', 'target_origin_other', 'target_gender_men',\n",
    "    'target_gender_non_binary', 'target_gender_transgender_men',\n",
    "    'target_gender_transgender_unspecified', 'target_gender_transgender_women',\n",
    "    'target_gender_women', 'target_gender_other', 'target_sexuality_bisexual',\n",
    "    'target_sexuality_gay', 'target_sexuality_lesbian', 'target_sexuality_straight',\n",
    "    'target_sexuality_other', 'target_disability_physical', 'target_disability_cognitive',\n",
    "    'target_disability_neurological', 'target_disability_visually_impaired',\n",
    "    'target_disability_hearing_impaired', 'target_disability_unspecific',\n",
    "    'target_disability_other'\n",
    "]\n",
    "\n",
    "# Helper function to classify the score based on the paper's logic\n",
    "def classify_score(score):\n",
    "    if score > 0.5:\n",
    "        return \"hateful\"\n",
    "    if score < -1.0:\n",
    "        return \"supportive\"\n",
    "    return \"neutral\"\n",
    "\n",
    "# 3. Create the function to transform each row of the DataFrame\n",
    "def create_gold_standard_record(row):\n",
    "    # Create the 'overall' object\n",
    "    overall = {\n",
    "        \"label\": classify_score(row['hate_speech_score']),\n",
    "        \"hate_speech_score\": row['hate_speech_score']\n",
    "    }\n",
    "    \n",
    "    # Create the 'facets' object\n",
    "    facets = {col: row[col] for col in FACET_COLUMNS}\n",
    "    \n",
    "    # Create the 'targets' object (ensuring columns exist)\n",
    "    targets = {col: bool(row[col]) for col in TARGET_COLUMNS if col in row}\n",
    "    \n",
    "    # Assemble the final record as a dictionary\n",
    "    return {\n",
    "        \"comment_id\": row['comment_id'],\n",
    "        \"text\": row['text'],\n",
    "        \"overall\": overall,\n",
    "        \"facets\": facets,\n",
    "        \"targets\": targets\n",
    "    }\n",
    "\n",
    "# 4. Apply the function to each row of the DataFrame\n",
    "print(\"Applying the transformation to each row of the DataFrame...\")\n",
    "gold_records = df.apply(create_gold_standard_record, axis=1).tolist()\n",
    "\n",
    "print(\"\\nExample of a processed record:\")\n",
    "print(json.dumps(gold_records[0], indent=2))\n",
    "\n",
    "output_file = \"gold_benchmark_dataset.jsonl\"\n",
    "print(f\"\\nSaving the {len(gold_records)} records to '{output_file}'...\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for record in gold_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86013981",
   "metadata": {},
   "source": [
    "# Next Steps: Benchmarking with unfinetuned models and calculate metrics against gold standard\n",
    "\n",
    "Standardized prompt:\n",
    "\n",
    "```You are an expert hate speech analyst. Your task is to analyze the provided text and return ONLY a valid JSON object that strictly follows the schema below. \n",
    "Do not include any explanations, markdown formatting, or text outside of the JSON object.\n",
    "\n",
    "=========================\n",
    "IMPORTANT INSTRUCTIONS\n",
    "=========================\n",
    "1. The output must be **valid JSON**, with no markdown or extra commentary.\n",
    "2. Use the exact field names and types described below.\n",
    "3. Each value must follow its correct type:\n",
    "   - Floats → only for `score`\n",
    "   - Integers → only for all values in `facets` (must be whole numbers, not floats)\n",
    "   - Booleans → only for all values in `targets` (`true` or `false`, lowercase)\n",
    "   - Strings → only for `label` (must be one of: \"supportive\", \"neutral\", \"hateful\")\n",
    "\n",
    "=========================\n",
    "OVERALL SCORE AND LABEL\n",
    "=========================\n",
    "Produce a single signed float named `\"score\"` and a string `\"label\"` inside `\"overall\"`.  \n",
    "\n",
    "**Scoring Rules:**\n",
    "- NEGATIVE float: `< -1` → Supportive content (e.g. `-1.35`)\n",
    "- POSITIVE float: `> 0.5` → Hateful content (e.g. `1.47`)\n",
    "- NEAR ZERO float: `-1 <= score <= 0.5` → Neutral content (e.g. `0.12`, `-0.08`)\n",
    "\n",
    "**Label Rules:**\n",
    "- If `score < -1`, then `\"label\": \"supportive\"`\n",
    "- If `-1 <= score <= 0.5`, then `\"label\": \"neutral\"`\n",
    "- If `score > 0.5`, then `\"label\": \"hateful\"`\n",
    "\n",
    "=========================\n",
    "FACETS (0-4 SCALE)\n",
    "=========================\n",
    "Each facet must be an **integer** from 0 to 4 (no decimals).  \n",
    "Use this scale strictly:\n",
    "- 0 = Absent  \n",
    "- 1 = Mild  \n",
    "- 2 = Clear  \n",
    "- 3 = Severe  \n",
    "- 4 = Extreme  \n",
    "\n",
    "Example: `\"insult\": 2`\n",
    "Do NOT output `\"insult\": 2.0` or `\"insult\": \"2\"`\n",
    "\n",
    "=========================\n",
    "TARGETS (BOOLEAN FLAGS)\n",
    "=========================\n",
    "Each target field must be a **boolean** (`true` or `false`) and only set to true if that group is explicitly targeted.\n",
    "\n",
    "=========================\n",
    "JSON SCHEMA (MUST MATCH EXACTLY)\n",
    "=========================\n",
    "{\n",
    "  \"overall\": {\n",
    "    \"score\": 0.00,\n",
    "    \"label\": \"neutral\"\n",
    "  },\n",
    "  \"facets\": {\n",
    "    \"sentiment\": 0,\n",
    "    \"respect\": 0,\n",
    "    \"insult\": 0,\n",
    "    \"humiliate\": 0,\n",
    "    \"status\": 0,\n",
    "    \"dehumanize\": 0,\n",
    "    \"violence\": 0,\n",
    "    \"genocide\": 0,\n",
    "    \"attack_defend\": 0,\n",
    "    \"hatespeech\": 0\n",
    "  },\n",
    "  \"targets\": {\n",
    "    \"target_race_asian\": false,\n",
    "    \"target_race_black\": false,\n",
    "    \"target_race_latinx\": false,\n",
    "    \"target_race_middle_eastern\": false,\n",
    "    \"target_race_native_american\": false,\n",
    "    \"target_race_pacific_islander\": false,\n",
    "    \"target_race_white\": false,\n",
    "    \"target_race_other\": false,\n",
    "    \"target_religion_atheist\": false,\n",
    "    \"target_religion_buddhist\": false,\n",
    "    \"target_religion_christian\": false,\n",
    "    \"target_religion_hindu\": false,\n",
    "    \"target_religion_jewish\": false,\n",
    "    \"target_religion_mormon\": false,\n",
    "    \"target_religion_muslim\": false,\n",
    "    \"target_religion_other\": false,\n",
    "    \"target_origin_immigrant\": false,\n",
    "    \"target_origin_migrant_worker\": false,\n",
    "    \"target_origin_specific_country\": false,\n",
    "    \"target_origin_undocumented\": false,\n",
    "    \"target_origin_other\": false,\n",
    "    \"target_gender_men\": false,\n",
    "    \"target_gender_non_binary\": false,\n",
    "    \"target_gender_transgender_men\": false,\n",
    "    \"target_gender_transgender_unspecified\": false,\n",
    "    \"target_gender_transgender_women\": false,\n",
    "    \"target_gender_women\": false,\n",
    "    \"target_gender_other\": false,\n",
    "    \"target_sexuality_bisexual\": false,\n",
    "    \"target_sexuality_gay\": false,\n",
    "    \"target_sexuality_lesbian\": false,\n",
    "    \"target_sexuality_straight\": false,\n",
    "    \"target_sexuality_other\": false,\n",
    "    \"target_age_children\": false,\n",
    "    \"target_age_teenagers\": false,\n",
    "    \"target_age_young_adults\": false,\n",
    "    \"target_age_middle_aged\": false,\n",
    "    \"target_age_seniors\": false,\n",
    "    \"target_age_other\": false,\n",
    "    \"target_disability_physical\": false,\n",
    "    \"target_disability_cognitive\": false,\n",
    "    \"target_disability_neurological\": false,\n",
    "    \"target_disability_visually_impaired\": false,\n",
    "    \"target_disability_hearing_impaired\": false,\n",
    "    \"target_disability_unspecific\": false,\n",
    "    \"target_disability_other\": false\n",
    "  }\n",
    "}\n",
    "\n",
    "=========================\n",
    "TEXT TO ANALYZE\n",
    "=========================\n",
    "{text}```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e3a7c",
   "metadata": {},
   "source": [
    "# Benchmarks:\n",
    "\n",
    "Overall Assessment:\n",
    "Label: We'll calculate the Macro F1-Score and Accuracy for the overall.label field (\"hateful\", \"neutral\", \"supportive\")\n",
    "\n",
    "Facet Analysis (Ordinal):\n",
    "Accuracy: We'll calculate the Mean Absolute Error (MAE) for each of the 10 facets by comparing our gold integer values to the model's predicted integer values.\n",
    "\n",
    "Target Identification (Multi-Label):\n",
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8439748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/ucberkeley-dlab/measuring-hate-speech/measuring-hate-speech.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6db0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comment_id', 'annotator_id', 'platform', 'sentiment', 'respect', 'insult', 'humiliate', 'status', 'dehumanize', 'violence', 'genocide', 'attack_defend', 'hatespeech', 'hate_speech_score', 'text', 'infitms', 'outfitms', 'annotator_severity', 'std_err', 'annotator_infitms', 'annotator_outfitms', 'hypothesis', 'target_race_asian', 'target_race_black', 'target_race_latinx', 'target_race_middle_eastern', 'target_race_native_american', 'target_race_pacific_islander', 'target_race_white', 'target_race_other', 'target_race', 'target_religion_atheist', 'target_religion_buddhist', 'target_religion_christian', 'target_religion_hindu', 'target_religion_jewish', 'target_religion_mormon', 'target_religion_muslim', 'target_religion_other', 'target_religion', 'target_origin_immigrant', 'target_origin_migrant_worker', 'target_origin_specific_country', 'target_origin_undocumented', 'target_origin_other', 'target_origin', 'target_gender_men', 'target_gender_non_binary', 'target_gender_transgender_men', 'target_gender_transgender_unspecified', 'target_gender_transgender_women', 'target_gender_women', 'target_gender_other', 'target_gender', 'target_sexuality_bisexual', 'target_sexuality_gay', 'target_sexuality_lesbian', 'target_sexuality_straight', 'target_sexuality_other', 'target_sexuality', 'target_age_children', 'target_age_teenagers', 'target_age_young_adults', 'target_age_middle_aged', 'target_age_seniors', 'target_age_other', 'target_age', 'target_disability_physical', 'target_disability_cognitive', 'target_disability_neurological', 'target_disability_visually_impaired', 'target_disability_hearing_impaired', 'target_disability_unspecific', 'target_disability_other', 'target_disability', 'annotator_gender', 'annotator_trans', 'annotator_educ', 'annotator_income', 'annotator_ideology', 'annotator_gender_men', 'annotator_gender_women', 'annotator_gender_non_binary', 'annotator_gender_prefer_not_to_say', 'annotator_gender_self_describe', 'annotator_transgender', 'annotator_cisgender', 'annotator_transgender_prefer_not_to_say', 'annotator_education_some_high_school', 'annotator_education_high_school_grad', 'annotator_education_some_college', 'annotator_education_college_grad_aa', 'annotator_education_college_grad_ba', 'annotator_education_professional_degree', 'annotator_education_masters', 'annotator_education_phd', 'annotator_income_<10k', 'annotator_income_10k-50k', 'annotator_income_50k-100k', 'annotator_income_100k-200k', 'annotator_income_>200k', 'annotator_ideology_extremeley_conservative', 'annotator_ideology_conservative', 'annotator_ideology_slightly_conservative', 'annotator_ideology_neutral', 'annotator_ideology_slightly_liberal', 'annotator_ideology_liberal', 'annotator_ideology_extremeley_liberal', 'annotator_ideology_no_opinion', 'annotator_race_asian', 'annotator_race_black', 'annotator_race_latinx', 'annotator_race_middle_eastern', 'annotator_race_native_american', 'annotator_race_pacific_islander', 'annotator_race_white', 'annotator_race_other', 'annotator_age', 'annotator_religion_atheist', 'annotator_religion_buddhist', 'annotator_religion_christian', 'annotator_religion_hindu', 'annotator_religion_jewish', 'annotator_religion_mormon', 'annotator_religion_muslim', 'annotator_religion_nothing', 'annotator_religion_other', 'annotator_sexuality_bisexual', 'annotator_sexuality_gay', 'annotator_sexuality_straight', 'annotator_sexuality_other']\n"
     ]
    }
   ],
   "source": [
    "column_names_list = df.columns.tolist()\n",
    "print(column_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b6289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
